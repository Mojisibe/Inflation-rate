# -*- coding: utf-8 -*-
"""Milestone_B03_report

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JUlgSfxouLBT-lpN3xHSupV0PrUak3oo

## Milestone B03: Bayesian Logistic Regression on Survey Data

**1. Introduction**

This report details the application of the Bayesian logistic regression model developed in Milestone B02 to the survey data. The primary goal is to analysze the relationship between agreement with statements about the impact of delayed work information ('I_I') and a binary outcome('Változtatott-e önszántából munkahelyet 2022. január 1. óta?'). The results are compared with those from a logistic regression analysis.

**2. Data Preparation**

* The survey data was prvided by BG.
* Columns were renamed to a standardized format (C000, C004, C027, C079).
* The predictor variable 'I_I' was created by merging 'C027' (past experience) and 'C079' (present experience) using the 'merge_columns' function written by BG.
* The outcome variable 'C004' was transformed into binary outcome ('outcome_binary'), where "Igen" is mapping to 1 and "Nem" is mapping to 0.

    * First 5 rows of relevant columns:


        | C027            | C079            | I\_I            |
        | :---------------| :---------------| :---------------|
        | NaN             | Egyetértek      | Egyetértek      |
        | Egyetértek      | NaN             | Egyetértek      |
        | Nem értek egyet | NaN             | Nem értek egyet |
        | NaN             | Nem értek egyet | Nem értek egyet |
        | NaN             | Nem értek egyet | Nem értek egyet |

    * Unique values in the outcome columns (C004): `['Nem' 'Igen']`
    * First few rows with binary outcome:
        
        | C004  | outcome\_binary |
        | :-----| :---------------|
        | Nem   | 0               |
        | Nem   | 0               |
        | Igen  | 1               |
        | Nem   | 0               |
        | Nem   | 0               |
**3. Bayesian Regression Model**
* The Bayesian regression model from Milestone B02 was aapplied to the prepared data.
* Priors were chosen as follows:
    * Intercept: Normal(mu=0, sigma = 10)
    * Effect: Normal (mu = 0. sigma = 2)
    * sd\_fluctuation: HalfCauchy(beta=2)
* Sampling was performed using PyMC, with 2000 draws and 1000 tune steps

** Model Result**
* Model convergence was accessed using trace plots and R-hat values
* Posterior distributions were examined toestimate the effect of 'I_I on the outcome.
* Model fit was evaluated using WAIC, LOO and BIC.

    * Model Metrics:
        ```
        ## Survey Model Metrics

        ### WAIC

        Computed from 4000 posterior samples and 333 observations log-likelihood matrix.

                       Estimate  SE
         elpd_waic     -215.46   10.68
         p_loo         5.95

        ### LOO
         Computed  from 4000 posterior samples and 333 observations log-likelihood matrix.
                        Estimate  SE
              elpd_loo  -21.61    10.68
              p_loo     6.09

        ### BIC

        BIC: 440.23
        ```

        * Model Summary:
        ```
            |                   |mean   |sd    |hdi\_3%|hdi\_97%|mcse\_mean|mcse\_sd|ess\_bulk|ess\_tail|r\_hat|
            |-------------------|-------|------|-------|--------|----------|-------|----------|---------|------|
            |effect             |-0\.427|0\.557|-1\.598|0\.577  |0\.015    |0\.013    |1445\.0   |1209\.0  |1\.01|
            |intercept          |0\.6   |0\.412|-0\.1  |1\.404  |0\.017    |0\.012    |617\.0    |1257\.0|    1\.0|
            |level\_effects\[0\]|0\.0   |0\.0   |0\.0  |0\.0    |0\.0      |0\.0      |4000\.0   |4000\.0  |      |
            |level\_effects\[1\]|-0\.897|0\.445|-1\.791|-0\.171 |0\.018    |0\.012    |656\.0    |1263\.0  |1\.0  |
            |level\_effects\[2\]|-1\.354|0\.459|-2\.213|-0\.53  |0\.019    |0\.014    |563\.0    |1201\.0  |1\.0  |
            |level\_effects\[3\]|-1\.384|0\.489|-2\.243|-0\.421 |0\.018    |0\.013    |741\.0    |1284\.0  |1\.0  |
            |level\_effects\[4\]|-1\.792|1\.358|-4\.401|0\.668  |0\.035    |0\.028    |1487\.0   |1298\.0  |1\.0  |
            |sd\_fluctuation    |0\.897 |0\.76 |0\.084 |2\.134  |0\.029    |0\.021    |425\.0    |310\.0   |1\.01 |
        ```

**5. Comparison to logistic Regression classical**

        
* The classical logistic regression results are:

      ```
      Logistic regression                                     Number of obs =    265
                                                              LR chi2(1)    =   6.16
                                                              Prob > chi2   = 0.0130
      Log likelihood = -173.51852                             Pseudo R2     = 0.0174

      ------------------------------------------------------------------------------
          outcome | Odds ratio   Std. err.      z    P>|z|     [95% conf. interval]
      -------------+----------------------------------------------------------------
            group |   1.929535   .5114353     2.48   0.013     1.147721    3.243911
            _cons |   1.045455   .2204556     0.21   0.833     .6915312    1.580515
      ------------------------------------------------------------------------------
      Note: _cons estimates baseline odds.
      ```
* Comparison:
    * Direction of Effect: Both models indicate a positive relationship between 'I_I' and the outcome.
    * Sgnificance: The logistic regression shows a statistical significant effect (p - 0.013). The Bayesian model's 95% HDI for the 'effect' parameter (0.18 to 1.37) excludes zero, suggesting a credible effect.
    * Effect Size:
        * Logistic Regression: Odds Ratio = 1.93
        * Bayesian Regression Model: The mean odds ratio from the Bayesian model is 0.99, ith a95% HDI of [0.0444898 1.7667999].
    * Model Fit: WAIC/LOO (Bayesian) and Pseudo R^2 (Logistic) are not directly comparable.
**8. Conclusion**
The Bayesian regression model provides a valuable framework for analyzing the relationship between agreement with statements about information delay and the binary outcome. The results are consistent with the logistic regression, but the Bayesian approach offers a richer understanding of uncertainty.
"""

